---
title: about
---

## quick facts
**who**: jay kruer.

**what** (i am doing): building a [deep learning framework](https://github.com/tenstorrent/tt-metal/tree/main/tt-train) and
training LLMs at [tenstorrent](https://tenstorrent.com). we make chips that make deep
learning go brrrr on an open source sw stack at better perf/$ than our
competitors. here's a brief explanation gesturing at how we're able to do that:
if you're familiar with TPUs, you can think of it as what might happen if you
took a TPU and exploded its humongous SRAM and matmul engine over a sea of tiny
tiles which can talk to each other. many tiny SRAM strong! ðŸ¦§

**when**: now through ??? <span style="font-size: 5%;">[you tell me](/contact.html)</span>


**where**: bend, oregon.

**with whomst**: my wonderful fiancÃ© jaclyn and our dog zuzu. see [outsta](/outsta.html)
 for some pics of us in the wild :)
<br>
<br>

### before
i've worked as a formal verification engineer at tenstorrent and intel, and
before that as a research engineer at sifive.

i studied math/cs at reed college, where i wrote my
[thesis](https://github.com/jaykru/thesis) on the category-theoretic semantics
of lambda calculus, specifically as applied to the open normalization problem
for the simply-typed lambda calculus. it's pretty wild stuff, and i went to
great pains to make it approachable to someone with a cursory background in
programming language theory. check it out!

check out my [resume](/resume.html) for more.
